{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JOg7kv1wd5le"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","source":["from tensorflow.keras.datasets import cifar10\n","\n","# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(train_images.shape, train_labels.shape)\n","print(test_images.shape, test_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlRo5J5Ed9Dr","outputId":"5ae6bef2-dd1f-48cd-ac91-9a22b35eeb88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 32, 32, 3) (50000, 1)\n","(10000, 32, 32, 3) (10000, 1)\n"]}]},{"cell_type":"code","source":["# 이미지 값 변환\n","train_images_2 = np.array(train_images/255.0, dtype=np.float32)\n","test_images_2 = np.array(test_images/255.0, dtype=np.float32)\n","\n","# 라벨 값 변환\n","train_labels_2 = np.array(train_labels, dtype=np.float32)\n","test_labels_2 = np.array(test_labels, dtype=np.float32)"],"metadata":{"id":"oa8ynId6d_OC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 동일하게 원핫이나 이런거 해도 된다 -> 입출력 데이터의 차원을 알기만 하면 된다\n","train_labels_2 = train_labels.squeeze()\n","test_labels_2 = test_labels.squeeze()\n","\n","# from tensorflow.keras.utils import to_categorical\n","# train_labels_2 = to_categorical(train_labels_2)\n","# test_labels_2 = to_categorical(test_labels_2)"],"metadata":{"id":"uUMJAhz5eAZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_x, val_x, train_y, val_y = train_test_split(train_images_2, train_labels_2, test_size=0.2, random_state=1)\n","train_x.shape, val_x.shape, train_y.shape, val_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a9nwIwReB4a","outputId":"5882d5de-734f-4262-bb0d-a89cc8b825ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((40000, 32, 32, 3), (10000, 32, 32, 3), (40000,), (10000,))"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["사전훈련 모델 불러오기"],"metadata":{"id":"0aJf9YeoeHPh"}},{"cell_type":"code","source":["import tensorflow.keras.applications"],"metadata":{"id":"m1rrisxxajty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(tensorflow.keras.applications)"],"metadata":{"id":"qxWIHk3RakzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.densenet import DenseNet121\n","from tensorflow.keras.applications import ResNet50V2"],"metadata":{"id":"x37t18QZfkfB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"-B5wrKbWeJrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# include_top=False로 기존 imagenet용 classifier 층들을 다 제거\n","# weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용\n","\n","# 이쪽 분야는 사전 훈련 모델을 쓸때 base라고 한다\n","# 파라미터 1. 입력모양, 2. 분류기 가져올 건지\n","\n","\n","# 3. 이미 학습된 가중치도 가져오니 더 이상 건들이지 말라는 의미(이미 학습된 애를 가져와서 그대로 사용할 거다란 뜻) = vgg의 파라미터는 오차역전파로 수정하지 않겠다 -> 바꾸려면 None로 하고 에폭을 엄청 늘려야함\n","# + w는 이미지넷이라는 w를 가져온다\n","\n","base_model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n","# base_model = DenseNet121(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n","\n","\n","\n","\n","# 이모델은 flatten하고 dense하고 있는게 생략 되어있다 이걸 처리해 줘야한다 = 마지막 레이어를 처리해야함 = 미완성됨 모델을 내가 만드는 거임\n","bm_output = base_model.output # 모델의 끝부분이라는 의미"],"metadata":{"id":"xF-gzmN1eLL7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 컨브 레이어만 w가 100만개가 넘는다\n","base_model.summary()"],"metadata":{"id":"k1_haiO3Uetn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 글로벌 맥스풀링은 각 공간 차원이 1이 될 때까지 공간 차원에 평균 풀링을 적용하고 다른 차원은 변경하지 않고 그대로 둚.\n","# Flatten과 비슷한 기능을 함\n","\n","\n","#flatten이 단순하게 한줄로 세운다면 얘는 평균을 계산하면서 압축을 하면서 줄을 세움 = 계산식이 들어간 Flatten이다 = 전이 학습이 너무 깊으니깐 단순히 줄을 세우는게 아니라 압축을 하면서 줄을 세우자 이거임\n","#flatten을 써도 되지만 너무 깊을 때는 이걸 쓰는게 훨씬 성능이 좋음\n","output_layer = GlobalAveragePooling2D()(bm_output)\n","output_layer = Dense(50, activation='relu')(output_layer)\n","\n","# 역시 마지막은 클래스 개수에 맞추는 거고 + 이걸 봤을때 flatten하고 dense하는 걸 처리한다는 느낌이 확듬\n","output_layer = Dense(10, activation='softmax')(output_layer)\n","\n","model = Model(inputs=base_model.input, outputs=output_layer)# 모델의 시작부분이라는 의미"],"metadata":{"id":"Hm_7NzqYlL4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 사전 훈련 모델은 모델이 너무 깊어서 과적합을 줄이기 위해 학습률을 조정하여 과적합 방지를 도와줄 수 있다\n","model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOeoEM2JeTc5","outputId":"654da4d9-7cd3-4b70-ce16-6aa5563306bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["# 아까는 학습이 빨리 수렴됐는데 이번에는 엄청 오래걸린다\n","\n","batch_size = 64\n","epochs = 10\n","\n","history = model.fit(x=train_x, y=train_y, batch_size=batch_size, epochs=epochs, validation_data=(val_x, val_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WopkO3QZeU9g","outputId":"f65a1ae7-43c6-4c02-f230-8c58d9cd4d99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","625/625 [==============================] - 25s 38ms/step - loss: 1.8311 - accuracy: 0.2724 - val_loss: 1.5426 - val_accuracy: 0.4042\n","Epoch 2/20\n","625/625 [==============================] - 23s 37ms/step - loss: 1.2896 - accuracy: 0.5121 - val_loss: 1.1533 - val_accuracy: 0.5894\n","Epoch 3/20\n","625/625 [==============================] - 23s 37ms/step - loss: 1.0071 - accuracy: 0.6404 - val_loss: 1.0296 - val_accuracy: 0.6488\n","Epoch 4/20\n","625/625 [==============================] - 24s 38ms/step - loss: 0.8373 - accuracy: 0.7093 - val_loss: 0.8474 - val_accuracy: 0.7040\n","Epoch 5/20\n","625/625 [==============================] - 24s 38ms/step - loss: 0.7147 - accuracy: 0.7549 - val_loss: 0.8229 - val_accuracy: 0.7259\n","Epoch 6/20\n","625/625 [==============================] - 24s 38ms/step - loss: 0.6125 - accuracy: 0.7946 - val_loss: 0.7701 - val_accuracy: 0.7521\n","Epoch 7/20\n","625/625 [==============================] - 24s 38ms/step - loss: 0.5521 - accuracy: 0.8174 - val_loss: 0.8162 - val_accuracy: 0.7390\n","Epoch 8/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.4746 - accuracy: 0.8442 - val_loss: 0.7183 - val_accuracy: 0.7765\n","Epoch 9/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.4270 - accuracy: 0.8606 - val_loss: 0.7892 - val_accuracy: 0.7646\n","Epoch 10/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.3772 - accuracy: 0.8777 - val_loss: 0.7123 - val_accuracy: 0.7877\n","Epoch 11/20\n","625/625 [==============================] - 25s 40ms/step - loss: 0.3271 - accuracy: 0.8927 - val_loss: 0.7440 - val_accuracy: 0.7876\n","Epoch 12/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.3047 - accuracy: 0.9009 - val_loss: 0.7731 - val_accuracy: 0.7813\n","Epoch 13/20\n","625/625 [==============================] - 25s 39ms/step - loss: 0.2847 - accuracy: 0.9093 - val_loss: 0.8457 - val_accuracy: 0.7837\n","Epoch 14/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.2529 - accuracy: 0.9220 - val_loss: 0.7886 - val_accuracy: 0.7853\n","Epoch 15/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.2253 - accuracy: 0.9286 - val_loss: 0.8052 - val_accuracy: 0.7923\n","Epoch 16/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.2047 - accuracy: 0.9350 - val_loss: 0.8514 - val_accuracy: 0.7815\n","Epoch 17/20\n","625/625 [==============================] - 24s 39ms/step - loss: 0.2024 - accuracy: 0.9366 - val_loss: 0.8780 - val_accuracy: 0.7899\n","Epoch 18/20\n","625/625 [==============================] - 25s 40ms/step - loss: 0.1716 - accuracy: 0.9472 - val_loss: 0.9934 - val_accuracy: 0.7895\n","Epoch 19/20\n","625/625 [==============================] - 25s 41ms/step - loss: 0.1736 - accuracy: 0.9473 - val_loss: 0.9315 - val_accuracy: 0.7973\n","Epoch 20/20\n","625/625 [==============================] - 25s 39ms/step - loss: 0.1641 - accuracy: 0.9481 - val_loss: 0.9437 - val_accuracy: 0.7925\n"]}]},{"cell_type":"code","source":["# 테스트 데이터로 성능 평가\n","model.evaluate(test_images_2, test_labels_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTrx3ODItZ8m","outputId":"a2fe5a0f-9b6b-4f2f-bc77-de36b5fd94e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 9ms/step - loss: 0.9692 - accuracy: 0.7910\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9692130088806152, 0.7910000085830688]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# 결과 한 에폭당 25초\n","# 정확도 : 점점 수렴하다가 79에서 멈춤 -> cnn cifar10이 74가 나왔는데 이모델을 사용하니 내가 굳이 딥러닝 층을 구현하지 않고 가볍게 썼는데 오히려 성능이 더 좋아짐!!\n","# 앞으로 코드를 다 구현하는 일은 없을 거다 나에게 맞는 모델을 찾아서 불러와서 돌리는 경우가 훨씬 많고 오히려 성능이 더 좋을 것이다 but 그 모델을 내 맘대로 바꾸는데 모델 구성법을 알아야한다"],"metadata":{"id":"SM-kKe_YYdjx"},"execution_count":null,"outputs":[]}]}